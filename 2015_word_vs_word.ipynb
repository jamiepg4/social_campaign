{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from pymongo import MongoClient\n",
    "from collections import Counter, defaultdict\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twitter_blacklist = set(['BobWhitaker2016', 'DrJillStein', 'JoeBiden', 'TheRealRoseanne',\n",
    "                         'eugenepuryear', 'glorialariva', 'system.indexes', 'verminsupreme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fb_blacklist = set(['Eugene4DC', 'drjillstein', 'VerminSupreme', 'RobertWWhitaker', 'system.indexes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "instagram_blacklist = set(['eugene4dc', 'officialroseannebarr', 'system.indexes', 'vp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "handle_dict = requests.get('http://api.electionscrape.com/handles').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_twitter_text():\n",
    "    tweet_dict = defaultdict(list)\n",
    "    \n",
    "    for coll_name in client.twitter.collection_names():\n",
    "        if not coll_name in twitter_blacklist:\n",
    "            # Get candidate slug\n",
    "            for key in handle_dict:\n",
    "                if coll_name in handle_dict[key]['twitter']:\n",
    "                    cand_slug = key\n",
    "                    \n",
    "            coll = client.twitter[coll_name]\n",
    "            for doc in coll.find():\n",
    "                dt_str = doc['created_at']\n",
    "                # if 2015\n",
    "                if dt_str.split(' ').pop() == '2015':\n",
    "                    tweet_dict[cand_slug].append(doc['text'])\n",
    "    \n",
    "    return tweet_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_facebook_text():\n",
    "    fb_dict = defaultdict(list)\n",
    "    \n",
    "    for coll_name in client.facebook.collection_names():\n",
    "        if not coll_name in fb_blacklist:\n",
    "            # Get candidate slug\n",
    "            for key in handle_dict:\n",
    "                if coll_name in handle_dict[key]['facebook']:\n",
    "                    cand_slug = key\n",
    "                    \n",
    "            coll = client.facebook[coll_name]\n",
    "            for doc in coll.find():\n",
    "                dt_str = doc['created_time']\n",
    "                # if 2015\n",
    "                if dt_str.split('-')[0] == '2015':\n",
    "                    if 'message' in doc:\n",
    "                        fb_dict[cand_slug].append(doc['message'])\n",
    "    \n",
    "    return fb_dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_instagram_text():\n",
    "    insta_dict = defaultdict(list)\n",
    "    \n",
    "    for coll_name in client.instagram.collection_names():\n",
    "        if not coll_name in instagram_blacklist:\n",
    "            # Get candidate slug\n",
    "            for key in handle_dict:\n",
    "                if coll_name in handle_dict[key]['instagram']:\n",
    "                    cand_slug = key\n",
    "            \n",
    "#             print coll_name\n",
    "            coll = client.instagram[coll_name]\n",
    "            for doc in coll.find():\n",
    "                utc_secs = float(doc['created_time'])\n",
    "                year = datetime.datetime.fromtimestamp(utc_secs).year\n",
    "                # if 2015\n",
    "                if year == 2015 and doc['caption']:\n",
    "                        insta_dict[cand_slug].append(doc['caption']['text'])\n",
    "    \n",
    "    return insta_dict   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter_dict = get_twitter_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fb_dict = get_facebook_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "insta_dict = get_instagram_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_dict = defaultdict(list)\n",
    "list_of_dicts = [twitter_dict, fb_dict, insta_dict]\n",
    "\n",
    "for d in list_of_dicts:\n",
    "    for key in d:\n",
    "        text_dict[key].extend(d[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get stopwords\n",
    "stopwords = set(re.findall(r'\\w+', open('stopwords.txt', 'r').read()) + map(str, range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert all text to one big string\n",
    "all_text_str = ' '.join(map(lambda x: ' '.join(x), text_dict.values())).lower()\n",
    "\n",
    "# Remove urls\n",
    "all_text_str = re.sub(r'http[^\\s]+', '', all_text_str)\n",
    "\n",
    "# Tokenize\n",
    "all_tokens = filter(lambda x: not x in stopwords, re.findall(r'\\w+', all_text_str))\n",
    "\n",
    "# Count\n",
    "all_word_count = Counter(all_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terrorism vs. Economy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3341\n"
     ]
    }
   ],
   "source": [
    "terrorism = all_word_count['terrorism']\n",
    "terrorist = all_word_count['terrorist']\n",
    "terrorists = all_word_count['terrorists']\n",
    "attack = all_word_count['attack']\n",
    "security = all_word_count['security']\n",
    "threat = all_word_count['threat']\n",
    "\n",
    "terror_tot = terrorism + terrorist + attack + terrorists + security + threat\n",
    "print terror_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3418\n"
     ]
    }
   ],
   "source": [
    "economy = all_word_count['economy']\n",
    "job = all_word_count['job']\n",
    "jobs = all_word_count['jobs']\n",
    "wage = all_word_count['wage']\n",
    "wages = all_word_count['wages']\n",
    "labor = all_word_count['labor']\n",
    "\n",
    "econ_tot = economy + jobs + wage + wages + job + labor\n",
    "print econ_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guys vs. Gals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1927\n"
     ]
    }
   ],
   "source": [
    "# some words likely on blacklist \n",
    "\n",
    "#gals_tot = all_word_count[('woman', 'she', 'her', 'girl', 'gal')]\n",
    "\n",
    "#gals=set[('woman', 'she', 'her', 'girl', 'gal')]\n",
    "#gals_tot = all_word_count[lambda x: x in gals]\n",
    "\n",
    "woman = all_word_count['woman']\n",
    "she = all_word_count['she']\n",
    "her = all_word_count['her']\n",
    "girl = all_word_count['girl']\n",
    "gal = all_word_count['gal']\n",
    "\n",
    "gals_tot = woman + she + her + girl + gal\n",
    "print gals_tot\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5614\n"
     ]
    }
   ],
   "source": [
    "# some words likely on blacklist \n",
    "man = all_word_count['man']\n",
    "he = all_word_count['he']\n",
    "him = all_word_count['him']\n",
    "boy = all_word_count['boy']\n",
    "guy = all_word_count['guy']\n",
    "\n",
    "guys_tot = man + he + him + boy + guy\n",
    "print guys_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Family vs. Corporation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2649\n"
     ]
    }
   ],
   "source": [
    "family = all_word_count['family']\n",
    "families = all_word_count['families']\n",
    "child = all_word_count['child']\n",
    "kid = all_word_count['kid']\n",
    "home = all_word_count['home']\n",
    "\n",
    "family_tot = family + child + kid + home + families\n",
    "print family_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310\n"
     ]
    }
   ],
   "source": [
    "corporation = all_word_count['corporation']\n",
    "corporate = all_word_count['corporate']\n",
    "company = all_word_count['company']\n",
    "business = all_word_count['business']\n",
    "ceo = all_word_count['ceo']\n",
    "executive = all_word_count['executive']\n",
    "\n",
    "bus_tot = corporation + corporate + company + business + ceo + executive\n",
    "print bus_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
